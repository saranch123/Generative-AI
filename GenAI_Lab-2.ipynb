{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOVic/BDE7t7nm4FBP6KeXT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a5IHEN2hi95A","executionInfo":{"status":"ok","timestamp":1768882172943,"user_tz":-330,"elapsed":5342,"user":{"displayName":"Saran Chekka B Tech 23","userId":"02731501057685101843"}},"outputId":"b3e8eb50-6812-4fda-9a3d-3c9b234bacbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip -q install --upgrade langchain langchain-core langchain-groq\n"]},{"cell_type":"code","source":["import os, getpass\n","os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter GROQ_API_KEY: \")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6kdDPmbluMD","executionInfo":{"status":"ok","timestamp":1768882251615,"user_tz":-330,"elapsed":2189,"user":{"displayName":"Saran Chekka B Tech 23","userId":"02731501057685101843"}},"outputId":"0a98c0f2-8b4b-4dbe-b213-d38baf50d9bb"},"execution_count":18,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter GROQ_API_KEY: ··········\n"]}]},{"cell_type":"code","source":["from langchain_groq import ChatGroq\n","from langchain_core.prompts import PromptTemplate\n","\n","llm = ChatGroq(\n","    model=\"llama-3.1-8b-instant\",   # other options below\n","    temperature=0.3\n",")\n","\n","prompt = PromptTemplate(\n","    input_variables=[\"topic\"],\n","    template=\"\"\"\n","Explain {topic} in simple words for a university lab record.\n","\n","Include:\n","1) Definition (2-3 lines)\n","2) One real-life example\n","3) Simple working steps (4-5)\n","4) 5 practice questions\n","\"\"\"\n",")\n","\n","chain = prompt | llm\n","\n","res = chain.invoke({\"topic\": \"LangChain\"})\n","print(res.content)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyLWlKzwlytr","executionInfo":{"status":"ok","timestamp":1768882289989,"user_tz":-330,"elapsed":1599,"user":{"displayName":"Saran Chekka B Tech 23","userId":"02731501057685101843"}},"outputId":"3e8072b6-a137-4f7d-f532-76b24811feac"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["**Lab Record: LangChain**\n","\n","**Definition:**\n","LangChain is an open-source Python library that enables developers to build conversational AI models by connecting multiple AI components together. It provides a flexible framework for creating custom conversational workflows, allowing users to integrate various AI models and tools to achieve complex tasks.\n","\n","**Real-Life Example:**\n","Imagine you're building a chatbot for a customer support system. You want the chatbot to be able to answer questions about products, provide recommendations, and even book appointments. LangChain allows you to connect different AI models, such as a language model for answering questions, a recommendation engine for suggesting products, and a scheduling API for booking appointments.\n","\n","**Simple Working Steps:**\n","\n","1. **Define the Conversational Workflow**: Determine the sequence of AI components that will be used to achieve the desired task.\n","2. **Choose the AI Models**: Select the specific AI models that will be used in each component of the workflow.\n","3. **Connect the Components**: Use LangChain to connect the chosen AI models and define how they will interact with each other.\n","4. **Train and Test the Workflow**: Train the AI models and test the conversational workflow to ensure it's working as expected.\n","5. **Deploy the Chatbot**: Deploy the conversational workflow as a chatbot, either on a website or through a messaging platform.\n","\n","**Practice Questions:**\n","\n","1. What is the primary function of LangChain in building conversational AI models?\n","a) To train AI models\n","b) To connect AI components\n","c) To deploy chatbots\n","d) To recommend products\n","\n","Answer: b) To connect AI components\n","\n","2. Which of the following is an example of a conversational workflow?\n","a) A single language model answering questions\n","b) A chatbot that provides product recommendations and books appointments\n","c) A machine learning algorithm for image classification\n","d) A natural language processing (NLP) tool for sentiment analysis\n","\n","Answer: b) A chatbot that provides product recommendations and books appointments\n","\n","3. What is the benefit of using LangChain to connect AI components?\n","a) It reduces the complexity of building conversational AI models\n","b) It increases the cost of building conversational AI models\n","c) It requires more expertise in AI development\n","d) It limits the flexibility of conversational workflows\n","\n","Answer: a) It reduces the complexity of building conversational AI models\n","\n","4. Which of the following is an example of an AI model that can be used in a conversational workflow?\n","a) A language model for answering questions\n","b) A machine learning algorithm for image classification\n","c) A natural language processing (NLP) tool for sentiment analysis\n","d) All of the above\n","\n","Answer: d) All of the above\n","\n","5. What is the final step in building a conversational workflow using LangChain?\n","a) Defining the conversational workflow\n","b) Choosing the AI models\n","c) Connecting the components\n","d) Deploying the chatbot\n","\n","Answer: d) Deploying the chatbot\n"]}]}]}